{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGHohjVDJq2m"
   },
   "source": [
    "# Week 9\n",
    "# Reinforcement Learning \n",
    "* what is RL? \n",
    "* Does it have to do anything with Machine Learning?\n",
    "* Reinforcement learing is a branch of machine learning, But what makes it a branch? \n",
    " * There is no **supervisor**, only a <font color='skyblue'> **Reward**</font> signal\n",
    "* RL is active, Not passive!\n",
    "* Interactions are often squential \n",
    "* you have the <font color='skyblue'> **Agent** </font> that interacts with the <font color='skyblue'> **Environment** </font>\n",
    "* Agent takes an <font color='skyblue'> **Action** </font> and in return gets **reward** and a new <font color='skyblue'> **State** </font>\n",
    "* **Goal** is to select sequence of actions that will **maximize** the reward\n",
    "* In some cases reward can be **delayed**\n",
    "* We need to think <font color=\"lightgreen\"> **long-term** </font> instead of <font color=\"red\"> **short-term** </font> in order to achive our goal \n",
    "* But how do we know from which action we can benefit the most? \n",
    " * **Policy**: a strategy that an agent uses in pursue it's goal\n",
    "* We need some kind of function to refer in order to make desicion.\n",
    "<!-- \n",
    "![RL cycle.png](https://drive.google.com/uc?id=1o0gGJQEr1YUUkeaK5OzOzKIodJAV326Y) -->\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJGHZoItaiSD"
   },
   "source": [
    "# [Challenge Activity:]\n",
    "\n",
    "The best way to learn and [to avoid the illusion of competence](https://fr.coursera.org/lecture/learning-how-to-learn/illusions-of-competence-BuFzf) **is to test yourself.** This will help you to find **where you need to reinforce your knowledge**. \n",
    "\n",
    "\n",
    "### Q1: What is Reinforcement Learning?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "  \n",
    "Reinforcement learning is a **framework for solving control tasks (also called decision problems)** by building agents that learn from the environment by interacting with it through trial and error and **receiving rewards (positive or negative) as unique feedback**.\n",
    "  \n",
    "</details>\n",
    "\n",
    "### Q2: Define the RL Loop\n",
    "\n",
    "<img src=\"assets/exercise_rl_loop.jpeg\" alt=\"Exercise RL Loop\"/>\n",
    "\n",
    "\n",
    "At every step:\n",
    "- Our Agent receives _state data_ from the environment\n",
    "- Based on that _state data_ the Agent takes an _action_\n",
    "- Our Agent will move to the right\n",
    "- The Environment goes to a _new state_\n",
    "- The Environment gives _a reward_ to the Agent\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "<img src=\"assets/exercise_rl_loop_2.jpeg\" alt=\"Exercise RL Solution\"/>\n",
    "  \n",
    "\n",
    "At every step:\n",
    "- Our Agent receives **state s0** from the environment\n",
    "- Based on that **state s0** the Agent takes an **action a0**\n",
    "- Our Agent will move to the right\n",
    "- The Environment goes to a **new state s1**\n",
    "- The Environment gives **a reward r1** to the Agent\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "### Q3: What's the difference between a state and an observation?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "  \n",
    "- *The state* is a **complete description of the state of the world** (there is no hidden information), in a fully observed environment. For instance, in chess game, we receive a state from the environment since we have access to the whole checkboard information.\n",
    "  \n",
    "- *The observation* is a **partial description of the state**. In a partially observed environment. For instance, in Super Mario Bros, we only see a part of the level close to the player, so we receive an observation.\n",
    "\n",
    "<img src=\"assets/observation_space_1.jpeg\" alt=\"Observation Space Recap\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "### Q4: A task is an instance of a Reinforcement Learning problem. What are the two types of tasks?\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "  \n",
    "- *Episodic task* : we have a **starting point and an ending point (a terminal state)**. This creates an episode: a list of States, Actions, Rewards, and new States. For instance, think about Super Mario Bros: an episode begin at the launch of a new Mario Level and ending when youâ€™re killed or you reached the end of the level.\n",
    "  \n",
    "- *Continuous task* : these are tasks that **continue forever (no terminal state)**. In this case, the agent must learn how to choose the best actions and simultaneously interact with the environment.\n",
    "  \n",
    "<img src=\"assets/types_of_tasks.jpeg\" alt=\"Task\"/>\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T06:09:23.937290Z",
     "start_time": "2025-07-25T06:09:23.935736Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
